---
title: "Efficient R Programming"
author: Colin Gillespie ([\@csgillespie](https://twitter.com/csgillespie))
output: ioslides_presentation
css: [css/left.css, css/welcome.css]
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Slides: Welcome}
-->

```{r echo=FALSE}
completed = read.csv("extdata/typeform.csv")
setnicepar = function(mar=c(3,3,2,1), 
                      mgp=c(2,0.4,0), tck=-.01,
                      cex.axis=0.9, las=1, mfrow=c(1,1),...) {
  par(mar=mar, 
      mgp=mgp, tck=tck,
      cex.axis=cex.axis, las=las,mfrow=mfrow,...)
}
```

## Tutorial R Package

Contains copies of slides and exercises
```{r eval=FALSE}
install.packages("drat")
drat::addRepo("jr-packages")
install.packages("efficientTutorial")
```


## Who am I

  * Dr Colin Gillespie
    * Senior Statistics Lecturer, Newcastle University
    * Consultant at [Jumping Rivers](jumpingerivers.com)

## Jumping Rivers

  * Statistical and R consultancy
  * R, Scala, python, & Stan training
  * Predictive analytics
  * Dashboard development
  * In-house training
  
# Who are you? Time to make a friend

## Who are you?

```{r, echo=FALSE}
setnicepar()
tab = table(completed$list_iVD4_choice)
barplot(tab, col="steelblue")
```
We also have a _Transitionning Physicist_ in the room

## Functions & loops

```{r echo=FALSE}
setnicepar(mfrow=c(1, 2))
r_fun = factor(as.numeric(completed$opinionscale_nW40), levels=1:10)
barplot(table(r_fun), col="steelblue", main = "Functions", ylim=c(0, 40))
r_for = factor(as.numeric(completed$opinionscale_LMTT), levels=1:10)
barplot(table(r_for), col="steelblue", main = "Loops", ylim=c(0, 40))
```


## Other bits and pieces

  * Around 40% of people have built a package

  * Most people haven't used C/C++

## Todays tutorial

  * Small subset of efficient R programming course
  * Based https://github.com/csgillespie/efficientR

```{r eval=FALSE}
## Slides
browseVignettes("efficientTutorial")
```

## What we won't cover

 * Rcpp in depth
 * dplyr and friends
 * The joys of git and reproducible research
 * Pipes
 * Big data
 * Statistics

# Optimisation
## Optimisation

> The real problem is that programmers have spent far too much time worrying about
efficiency in the wrong places and at the wrong times; premature optimization is the
root of all evil (or at least most of it) in programming.

__Donald Knuth__

## Timing code

  * `system.time()`
  * `microbenchmark()`

##  `system.time()`

  * Easy to use

    ```{r}
    system.time(x <- rnorm(1000000)^2.3)
    ```

  * Hard to compare multiple benchmarks

##  `microbenchmark()`

```{r eval=FALSE}
microbenchmark::microbenchmark(times = 1000, 
                               unit = "ms", # milliseconds
           d_m[1,], d_df[1,], d_m[,1], d_df[,1])
#Unit: milliseconds
#      expr     min      lq    mean median      uq      max neval cld
#  d_m[1, ] 0.00437 0.00859 0.01494 0.0149 0.02044   0.0494  1000  a 
# d_df[1, ] 4.72234 5.06722 5.68170 5.3335 5.67679 109.3836  1000   b
#  d_m[, 1] 0.00615 0.00677 0.00777 0.0072 0.00817   0.0244  1000  a 
# d_df[, 1] 0.00649 0.00871 0.01281 0.0120 0.01538   0.0558  1000  a 
```

## useR! Resolution

> Never ask on Stackoverflow which method is faster!

## Todays Plan

  * Byte Compiling
  * Low hanging targets
  * Code Profiling
  * Parallel Computing
  * Rcpp











